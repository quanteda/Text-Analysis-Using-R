{
  "hash": "e984eb2b134e790f0e36bdc8e7422362",
  "result": {
    "markdown": "# Preface {.unnumbered}\n\nThe uses and means for analysing text, especially using quantitative and computational approaches, have exploded in recent years across the fields of academic, industry, policy, and other forms of research and analysis. Text mining and text analysis have become the focus of a major methodological wave of innovation in the fields of political science in particular, but also extending to finance, media and communications, and sociology.\n\nText analysis is a broad label for a wide range of tools applied to *textual* data, a form of structured data that is created from typically unstructured raw data in the form of natural language documents. It includes descriptive analysis, keyword analysis, topic analysis, measurement and scaling, clustering, text and vocabulary comparisons, or sentiment analysis. It may include causal analysis or predictive modelling. In its most advanced current forms, it extends to the natural language generation models that power the newest generation of artificial intelligence systems.\n\nThis book provides a practical guide introducing the fundamentals of text analysis methods and how to implement them using the R programming language. It covers a wide range of topics to provide a useful resource for a range of students from complete beginners to experienced users of R wanting to learn more advanced techniques.\n\n## Why R (and another book on text mining in R)? {.unnumbered}\n\nThis book is intended for a specific audience: those wishing to apply the methods of quantitative analysis and natural language processing text using the R language. Excellent alternatives exist, especially those in Python. So why use R for such a task?\n\nText mining tools for R have existed for many years, led by the venerable \\textbf{tm} package [@tmpackage]. In 2015, the first version of \\textbf{quanteda} was published on CRAN. Since then, the package has undergone three major versions, with each release improving its consistency, power, and usability. Starting with version 2, \\textbf{quanteda} split into a series of packages designed around its different functions (such as plotting, statistics, or machine learning), with \\textbf{quanteda} retaining the core text processing functions. Other popular alternatives exist, such as \\textbf{tidytext}, although as we explain in \\[further-tidy\\], \\textbf{quanteda} works perfectly well with tidyverse and other tidytext-like approaches.\n\nWhy another book about text analysis using R?\n\nWhy use R for this? When perfectly adequate packages exist for Python?\n\n(This might belong in the Introduction instead.)\n\nAnd why **quanteda**?\n\n## What to Expect from This Book {.unnumbered}\n\nThis book is meant to be as a practical resource for those confronting the practical challenges of text analysis for the first time, focusing on how to do this in R. Our main focus is on the **quanteda** package [@quantedaJOSS] and its extensions, although we also cover more general issues including a brief overview of the R functions required to get started quickly with practical text analysis We cover an introduction to the R language, for\n\n::: callout-note\nMany text analysis packages exist for the R programming language, but here our focus is on the **quanteda** package and its extensions. \"quanteda\" is a portmanteau name indicating the purpose of the package, which is the quantitative analysis of textual data.\n:::\n\n@benoit2020text provides a detailed overview of the analysis of textual data, and what distinguishes textual data from other forms of data. It also clearly articulates what is meant by treating text \"as data\" for analysis. This book and the approaches it presents are firmly geared toward this mindset. All of three of the authors are academics, although we also have experience working in industry or in applying text analysis for non-academic purposes. The typical reader may be a student of text analysis in the literal sense (of being an student) or in the general sense of someone studying techniques in order to improve their practical and conceptual knowledge.\n\nEach chapter is structured so to provide a continuity across each topic. For each main subject explained in a chapter, we clearly explain the objective of the chapter, then describe the text analytic methods in an applied fashion so that readers are aware of the workings of the method. We then provide practical examples, with detailed working code in R as to how to implement the method. Next, we identify any special issues involved in correctly applying the method, including how to hand the more complicated situations that may arise in practice. Finally, we provide further reading for readers wishing to learn more, and exercises for those wishing for hands-on practice, or for assigning these when using them in teaching environment. Our goal is to make the book is suitable for self-learning or to form the basis for teaching and learning in a course on applied text analysis.\n\n## Who This Book Is For {.unnumbered}\n\nPrerequisites. We don't assume any previous knowledge of text mining and very little knowledge of R, although it will help to start with some. Resources for complete beginners that we recommend include: ...\n\nOur orientation as social scientists, with a specialization in political text and political communications and media. But this book is for everyone: social scientists, computer scientists, scholars of digital humanities, researchers in marketing and management, and applied researchers working in policy, government, or business fields.\n\nHow to use the book depending on where the reader fits within the continuum of R experience and prior experience with text analysis.\n\n## How to Use This Book {.unnumbered}\n\n### Chapters Outline {.unnumbered}\n\n## Outline {.unnumbered}\n\nThe book is divided into seven sections. These group topics that we feel represent common stages of learning in text analysis, or similar groups of topics that different users will be drawn too. By grouping stages of learning, we make it possible also for intermediate or advanced users to jump to the section that interests them most, or to the sections where they feel they need additional learning.\n\nOur sections are:\n\n-   **(Working in R):** This section is designed for beginners to learn quickly the R required for the techniques we cover in the book, and to guide them in learning a proper R workflow for text analysis.\n\n-   **Acquiring texts:** Often described (by us at least) as the hardest problem in text analysis, we cover how to source documents, including from Internet sources, and to import these into R as part of the quantitative text analysis pipeline.\n\n-   **Managing textual data using quanteda:** In this section, we introduce the **quanteda** package, and cover each stage of textual data processing, from creating structured corpora, to tokenisation, and building matrix representations of these tokens. WE also talk about how to build and manage structured lexical resources such as dictionaries and stop word lists.\n\n-   **Exploring and describing texts:** How to get overviews of texts using summary statistics, exploring texts using keywords-in-context, extracting target words, and identifying key words.\n\n-   **Statistics for comparing texts:** How to characterise documents in terms of their lexical diversity. readability, similarity, or distance.\n\n-   **Machine learning for texts:** How to apply scaling models, predictive models, and classification models to textual matrices.\n\n-   **Further methods for texts:** Advanced methods including the use of natural language models to annotate texts, extract entities, or use word embeddings; integrating **quanteda** with \"tidy\" data approaches; and how to apply text analysis to \"hard\" languages such as Chinese (hard because of the high dimensional character set and the lack of whitespace to delimit words).\n\nFinally, in several **appendices**, we provide more detail about some tricky subjects, such as text encoding formats and working with regular expressions.\n\n### Chapter Structure {.unnumbered}\n\nOur approach in each chapter is split into the following components, which we apply in every chapter:\n\n-   Objectives. We explain the purpose of each chapter and what we believe are the most important learning outcomes.\n\n-   Methods. We clearly explain the methodological elements of each chapter, through a combination of high-level explanations, formulas, and references.\n\n-   Examples. We use practical examples, with R code, demonstrating how to apply the methods to realise the objectives.\n\n-   Issues. We identify any special issues, potential problems, or additional approaches that a user might face when applying the methods to their text analysis problem.\n\n-   Further Reading. In part because our scholarly backgrounds compel us to do so, and in part because we know that many readers will want to read more about each method, each chapter contains its own set of references and further readings.\n\n-   Exercises. For those wishing additional practice or to use this text as a teaching resource (which we strongly encourage!), we provide exercises that can be assigned for each chapter.\n\nThroughout the book, we will demonstrate with examples and build models using a selection of text data sets. A description of these data sets can be found in Appendix \\@ref(appendixdata).\n\nWe use three kinds of info boxes throughout the book to invite attention to notes and other ideas.\n\n::: callout-note\nThe first type of boxes provides notes, information on best practices, and links to further information.\n:::\n\n::: callout-warning\nSome boxes call out warnings or possible problems to watch out for.\n:::\n\n::: callout-important\nBoxes marked with hexagons highlight information about specific R packages and how they are used. We use **bold** for the names of R packages.\n:::\n\n### Data used in examples {.unnumbered}\n\nAll examples and code are bundled as a companion R package to the book, available from our [public GitHub repository](https://github.com/quanteda/Text-Analysis-Using-R/).\n\nWe largely rely on data from three sources:\n\n-   the built-in-objects from the **quanteda** package, such as the US Presidential Inaugural speech corpus;\\\n-   additional **quanteda** corpora from the **quanteda.corpora** package; and\\\n-   added corpora from the book's companion package.\n\nAlthough not commonly used, our scheme for naming data follows a very consistent scheme. The data objects being with `data`, have the object class as the second part of the name, such as `corpus`, and the third and final part of the data object name contains a description. The three elements are separated by the underscore (`_`) character. This means that any object is known by its name to be data, so that it shows up in the index of package objects (from the all-important help page, e.g. from `help(package = \"quanteda\")`) in one location, under \"d\". It also means that its object class is known from the name, without further inspection. So `data_dfm_lbgexample` is a dfm, while `data_corpus_inaugural` is clearly a corpus. We use this scheme and others like with an almost religious fervour, because we think that learning the functionality of a programming framework for NLP and quantitative text analysis is complicated enough without having also to decipher or remember a mishmash of haphazard and inconsistently named functions and objects. The more you use our software packages and specifically **quanteda**, the more you will come to appreciate the attention we have paid to implementing a consistent naming scheme for objects, functions, and their arguments as well as to their consistent functionality.\n\n### How to Contact Us {.unnumbered}\n\nPlease address comments and questions concerning this book by filing an issue on our GitHub page, <https://github.com/quanteda/Text-Analysis-Using-R/issues/>.\n\nAt this repository, you will also find instructions for installing the companion R package, **TAURbook**.\n\nFor more information about the authors or the Quanteda Initiative, visit our [website](https://quanteda.org).\n\n## Acknowledgements {.unnumbered}\n\nWe are so thankful for everything. Especially the ERC. Gush, gush.\n\n## Colophon {.unnumbered}\n\nThis book was written in [RStudio](https://www.rstudio.com/ide/) using [**Quarto**](https://quarto.org). The [website](https://quanteda.github.io/Text-Analysis-Using-R/) is hosted via [GitHub Pages](https://pages.github.com), and the complete source is available on [GitHub](https://github.com/quanteda/Text-Analysis-Using-R).\n\nThis version of the book was built with R version 4.2.1 (2022-06-23) and the following packages:\n\n\n\n::: {.cell-output-display}\n|Package             |Version |Source         |\n|:-------------------|:-------|:--------------|\n|quanteda            |3.2.2   |CRAN (R 4.2.0) |\n|quanteda.textmodels |0.9.4   |local          |\n|quanteda.textplots  |0.94.1  |CRAN (R 4.2.0) |\n|quanteda.textstats  |0.95    |CRAN (R 4.2.0) |\n|readtext            |0.81    |CRAN (R 4.2.0) |\n|stopwords           |2.3     |CRAN (R 4.2.0) |\n|tibble              |3.1.8   |CRAN (R 4.2.0) |\n|tidyverse           |1.3.2   |CRAN (R 4.2.0) |\n:::\n",
    "supporting": [
      "preface_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}